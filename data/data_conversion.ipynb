{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import join as pjoin\n",
    "from os.path import basename, isfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data conversion\n",
    "\n",
    "Converting .mat files into dataframes and then csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_csv(file):\n",
    "    mat = loadmat(file)\n",
    "    df = pd.DataFrame()\n",
    "    df['leftP'] = mat['leftP'][0]\n",
    "    df['rightP'] = mat['rightP'][0]\n",
    "    df['trial_response_side'] = mat['trialresponseside'][0]\n",
    "    df['trial_reward'] = mat['trialreward'][0]\n",
    "    return df\n",
    "\n",
    "def convert_timing_to_csv(df, file):\n",
    "    mat = loadmat(file)\n",
    "    df['cue_time'] = mat['cuetimes'][0]\n",
    "    # fill this column with nan\n",
    "    df['reward_time'] = np.nan\n",
    "    # assign rewarded non-nan trials' response time \n",
    "    # using the rewardtimes array from the mat file\n",
    "    df.loc[df['trial_reward'] == 1, 'reward_time'] = mat['rewardtimes'][0]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load .mat file\n",
    "for file in listdir(pjoin('behaviour_data', 'mat', 'task_info')):\n",
    "    path = pjoin('behaviour_data', 'mat', 'task_info', file)\n",
    "    df = convert_to_csv(path) \n",
    "    timing_path = pjoin('behaviour_data', 'mat', 'timing_info', file)\n",
    "    df = convert_timing_to_csv(df, timing_path)\n",
    "    df.to_csv(pjoin('behaviour_data', file.split('.')[0] + '.csv'), index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert spike times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import join as pjoin, isfile, basename\n",
    "\n",
    "from scipy.io import loadmat # type: ignore\n",
    "import numpy as np\n",
    "\n",
    "spike_data_root = pjoin('spike_times', 'sessions')\n",
    "\n",
    "for dir in listdir(spike_data_root):\n",
    "    file = pjoin(spike_data_root, dir, 'spts.mat')\n",
    "    if not isfile(file):\n",
    "        print(dir)\n",
    "        continue\n",
    "    mat = loadmat(file)\n",
    "    pfc = [np.array(i).flatten() for i in mat['pfcspts'][0]]\n",
    "    dms = [np.array(i).flatten() for i in mat['strspts'][0]]\n",
    "    pfc_np = np.empty(len(pfc), dtype=object)\n",
    "    pfc_np[:] = pfc\n",
    "    dms_np = np.empty(len(dms), dtype=object)\n",
    "    dms_np[:] = dms\n",
    "    np.save(pjoin(spike_data_root, dir, 'pfc.npy'), pfc_np)\n",
    "    np.save(pjoin(spike_data_root, dir, 'dms.npy'), dms_np)\n",
    "\n",
    "    for i in range(len(pfc)):\n",
    "        np.save(pjoin(spike_data_root, dir, 'pfc_{}.npy'.format(i)), pfc[i])\n",
    "    \n",
    "    for i in range(len(dms)):\n",
    "        np.save(pjoin(spike_data_root, dir, 'dms_{}.npy'.format(i)), dms[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Wei's summary table\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join as pjoin, isdir, basename, isfile\n",
    "from os import listdir, mkdir\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_excel('PPD_RTW_summary_table_Wei_06may2022_V2.xlsx')\n",
    "\n",
    "# rename the sessions to match the current format\n",
    "# from index_yy.mm.dd to indexyyyymmdd\n",
    "data['session'] = data['session'].apply(lambda x: x.replace('.', ''))\n",
    "data['session'] = data['session'].apply(lambda x: x.replace('_', '20'))\n",
    "\n",
    "# lower case the cell location + (cell ID -1)\n",
    "data['cell'] = data['Cell location'].apply(lambda x: x.lower()) + '_' + (data['Cell ID'] - 1).astype(dms)\n",
    "# remove the cell location and cell ID columns\n",
    "data = data.drop(columns=['Cell location', 'Cell ID'])\n",
    "\n",
    "# create another csv file storing stimulus, movement and reward correlation information\n",
    "stimulus_movement_reward = data[['session','Stimulus_related_firing_P_value','Movement_related_firing_P_value','Reward_related_firing_P_value']]\n",
    "# drop these columns from the original data\n",
    "data = data.drop(columns=['Stimulus_related_firing_P_value','Movement_related_firing_P_value','Reward_related_firing_P_value'])\n",
    "# rename the columns\n",
    "data = data.rename(columns={'Background_firing_correlation_Coefficient_with_PPD': 'background_firing_pearson_r', 'Background_firing_correlation_P_ value_with PPD': 'background_firing_p_values', 'Response_magnitude_correlation_Coefficient_with_PPD': 'response_firing_pearson_r', 'Response_magnitude_correlation_P_ value_with PPD':'response_firing_p_values'})\n",
    "\n",
    "\n",
    "# save the data in csv format\n",
    "data.to_csv('delta_P_correlation.csv', index=False)\n",
    "\n",
    "# save the stimulus, movement and reward correlation information in csv format\n",
    "stimulus_movement_reward.to_csv('stimulus_movement_reward_correlation.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
